//Content of agri_warp.py
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import matplotlib.gridspec as gridspec
import cv2
import numpy as np
import pickle as pickle
import glob
import math

from DBSCAN import *

ORIGINAL_SIZE = 1280, 720
WARPED_SIZE = 500, 600

imgs = ["../agri_images/0021.jpg"]
img = mpimg.imread(imgs[0])

# Get a new ROI for image, on which we apply Hough Transform.
# y=425 the upper bound (original_size[0] - 295).
# y=665 the lower bound (original_size[1] - 55).
# Make a triangle shape to identify lines that go off into vanishing point.
# MAKE NOTE THAT YOU ALWAYS DO WIDTH (X) THEN HEIGHT (Y).
roi_points = np.array([[0, ORIGINAL_SIZE[1] - 25],
                       [ORIGINAL_SIZE[0], ORIGINAL_SIZE[1] - 25],
                       [ORIGINAL_SIZE[0] // 2 + 10, ORIGINAL_SIZE[1] - 540]])
roi_points = np.array([[0, 360],
                       [1280, 360],
                       [1280, 665],
                       [0, 665]])
roi = np.zeros((720, 1280), np.uint8) # uint8 good for 0-255 so good for small numbers like colors
cv2.fillPoly(roi, [roi_points], 1)

# Employing Gaussian Blur
kernel = np.ones((3,3),np.uint8)
img = cv2.GaussianBlur(img,(3,3),2)
img = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)

#img = cv2.addWeighted(img, 2.3, np.zeros(img.shape, img.dtype), 0, 4)

# Might need to skip horizontal lines when doing HoughLine

# Canny + Hough Lines
img_HLS = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)
_h_channel = img_HLS[:, :, 0]
_l_channel  = img_HLS[:, :, 1]
_s_channel = img_HLS[:, :, 2]

# print(_l_channel[558][412])

_h_channel = cv2.equalizeHist(_h_channel)

low_thresh = 100
high_thresh = 200
# Better to do Canny on lightness channel
#_h_channel = cv2.erode(_h_channel,kernel,iterations = 1)
_h_channel = cv2.morphologyEx(_h_channel, cv2.MORPH_CLOSE, kernel)
_h_channel = cv2.GaussianBlur(_h_channel,(3,3),2)
_h_channel = cv2.GaussianBlur(_h_channel,(3,3),2)

kernel = np.ones((5,5),np.uint8)
edges = cv2.Canny(_h_channel, high_thresh, low_thresh)
edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)
new_img = cv2.bitwise_and(edges, edges, mask=roi)
plt.imshow(edges)
plt.show()
lines = cv2.HoughLinesP(new_img, 2, np.pi/180, 60, None, 60, 100)

Lhs = np.zeros((2, 2), dtype = np.float32)
Rhs = np.zeros((2, 1), dtype = np.float32)
x_max = 0
x_min = 2555    
left_av = []
right_av = []
dbscan_left = DBSCAN(50, 2)
dbscan_right = DBSCAN(50, 2)
for line in lines:
    for x1, y1, x2, y2 in line:
        # Average out the lines
        slope = (y2 - y1) / (x2 - x1)
        intercept = y1 - (slope * x1)
        if abs(slope) > 5 or slope == 0 or abs(slope) < 0.1:
            pass
        else:
            if slope > 0:
                dbscan_right.update(line)
            else:
                dbscan_left.update(line)

def fillAvgs(lines):
    l = []
    for i in range(len(lines)):
        line = lines[i]
        x1 = line[0]
        y1 = line[1]
        x2 = line[2]
        y2 = line[3]
        slope = (y2 - y1) / (x2 - x1)
        intercept = y1 - (slope * x1)
        l.append([slope, intercept])
        # cv2.line(img, (x1, y1), (x2, y2), (0, 255, 0), thickness = 2)
        return l
    
# l has (SLOPE, INTERCEPT) tuples

left_classes = dbscan_left.scan()
left_lines = dbscan_left.return_max(left_classes)
left_av = fillAvgs(left_lines)

right_classes = dbscan_right.scan()
right_lines = dbscan_right.return_max(right_classes)
right_av = fillAvgs(right_lines)

plt.imshow(img)
plt.show()

# Cont. Averaging Lines
left_fitted_av = np.average(left_av, axis=0)
right_fitted_av = np.average(right_av, axis=0)
print(left_fitted_av, right_fitted_av)

# Cont. Averaging Lines
top = ORIGINAL_SIZE[1] - 700
bot = ORIGINAL_SIZE[1] - 55
y1 = ORIGINAL_SIZE[1] - 55
y2 = ORIGINAL_SIZE[1] - 700
left_x1 = int((y1 - left_fitted_av[1]) / left_fitted_av[0])
left_x2 = int((y2 - left_fitted_av[1]) / left_fitted_av[0])
right_x1 = int((y1 - right_fitted_av[1]) / right_fitted_av[0])
right_x2 = int((y2 - right_fitted_av[1]) / right_fitted_av[0])
cv2.line(img, (left_x1, y1), (left_x2, int(y2)), (255, 0, 0), thickness = 2)
cv2.line(img, (right_x1, y1), (right_x2, int(y2)), (255, 0, 0), thickness = 2)
src_pts = np.float32([[0, 360],
                      [1280, 360],
                      [1280, 665.      ],
                      [0, 665.      ]])

dst_pts = np.float32([[0, 0], [WARPED_SIZE[0], 0],
                       [WARPED_SIZE[0], WARPED_SIZE[1]],
                       [0, WARPED_SIZE[1]]])

# Draw Trapezoid
cv2.polylines(img, [src_pts.astype(np.int32)],True, (0,200,100), thickness=5)

plt.imshow(img)
plt.show()

src_pts[0] += [-1, 1]
src_pts[1] += [1, 1]
M = cv2.getPerspectiveTransform(src_pts, dst_pts)
warped_img = cv2.warpPerspective(img, M, WARPED_SIZE)
f = warped_img
# M is what you will be using from now on.

# Next steps ...
# 1) Find mid-line between the two lane lines, serving as our reference line.
# 2) Warp and then hough for the reference line.
# 3) We already know the position of the current trajectory in warp (still just middle
#    of the image). Do some linear algebra to get distance in pixels.
# 4) Also still need to figure out pixel2meter.
#   a) Split project into 2: 1 for pixel2meter and 2 for running livestream

# Transform averaged points into warped coordinates.
# Endpoints for averaged lines
bot_left = np.array([left_x1, y1], dtype="float32")
top_left = np.array([left_x2, int(y2)], dtype="float32")
bot_right = np.array([right_x1, y1], dtype="float32")
top_right = np.array([right_x2, int(y2)], dtype="float32")

# Transforming above endpoints
bot_left = cv2.perspectiveTransform(np.array([[bot_left]]), M, WARPED_SIZE).squeeze()
top_left = cv2.perspectiveTransform(np.array([[top_left]]), M, WARPED_SIZE).squeeze()
bot_right = cv2.perspectiveTransform(np.array([[bot_right]]), M, WARPED_SIZE).squeeze()
top_right = cv2.perspectiveTransform(np.array([[top_right]]), M, WARPED_SIZE).squeeze()
cv2.line(f, bot_left.astype("int"), top_left.astype("int"), (0, 255, 0), 3)
cv2.line(f, bot_right.astype("int"), top_right.astype("int"), (0, 255, 0), 3)

mid_top = [int((top_left[0] + top_right[0]) / 2),
         int((top_left[1] + top_right[1]) / 2)]
mid_bot = [int((bot_left[0] + bot_right[0]) / 2),
         int((bot_left[1] + bot_right[1]) / 2)]

# Drawing mid-line
cv2.line(f, mid_top, mid_bot, (0, 0, 255), 3)
# Add current car trajectory
traj_bot = [f.shape[1] // 2, 600]
traj_top = [f.shape[1] // 2, 0]
cv2.line(f,traj_bot, traj_top, (0, 0, 255), 3)
x = traj_bot[0]
mid_slope = 0
if mid_top[0] - mid_bot[0] != 0:
    mid_slope = (mid_top[1] - mid_bot[1]) / (mid_top[0] - mid_bot[0])
else:
    mid_slope = (mid_top[1] - mid_bot[1]) * 1000
mid_int = mid_top[1] - mid_top[0] * mid_slope
y = x * mid_slope + mid_int
P = np.array([x, y])

# Calculating pixel distance between averaged line and trajectory line.
PA = np.array(traj_bot) - P
PB = np.array(mid_bot) - P

PB_mag = np.linalg.norm(PB)
PB_unit = PB / PB_mag
A_parallel = np.dot(PA, PB_unit) * PB_unit
A_parallel_pt = A_parallel + P

# Find Intercept

cv2.line(f,traj_bot, A_parallel_pt.astype("int"), (0, 0, 255), 3)

plt.imshow(f)
plt.show()






//--------------------
//Content of DBSCAN.py
import numpy as np

class DBSCAN:
    def __init__(self, eps, minPts):
        self.dbscan_dict = {}
        self.points = []
        self.minPts = minPts
        self.eps = eps

    def update(self, line):
        line = line.squeeze()
        x1 = line[0]
        y1 = line[1]
        x2 = line[2]
        y2 = line[3]
        mid_x = (x1 + x2) / 2
        mid_y = (y1 + y2) / 2
        self.dbscan_dict[(mid_x, mid_y)] = line
        self.points.append(np.array([mid_x, mid_y]))

    def scan(self):
        '''
        Cluster the dataset `D` using the DBSCAN algorithm.
        
        dbscan takes a dataset `D` (a list of vectors), a threshold distance
        `eps`, and a required number of points `MinPts`.
        
        It will return a list of cluster labels. The label -1 means noise, and then
        the clusters are numbered starting from 1.
        '''

        labels = [0]*len(self.points)

        # C is the ID of the current cluster.    
        C = 0
        
        # For each point P in the Dataset D...
        # ('P' is the index of the datapoint, rather than the datapoint itself.)
        for P in range(0, len(self.points)):
        
            # Only points that have not already been claimed can be picked as new 
            # seed points.    
            # If the point's label is not 0, continue to the next point.
            if not (labels[P] == 0):
                continue
            
            # Find all of P's neighboring points.
            NeighborPts = self.region_query(P)
            
            # If the number is below MinPts, this point is noise. 
            # This is the only condition under which a point is labeled 
            # NOISE--when it's not a valid seed point. A NOISE point may later 
            # be picked up by another cluster as a boundary point (this is the only
            # condition under which a cluster label can change--from NOISE to 
            # something else).
            if len(NeighborPts) < self.minPts:
                labels[P] = -1
            # Otherwise, if there are at least MinPts nearby, use this point as the 
            # seed for a new cluster.    
            else: 
                C += 1
                self.grow_cluster(labels, P, NeighborPts, C)
        
        # All data has been clustered!
        return labels


    def grow_cluster(self, labels, P, NeighborPts, C):
        '''
        Grow a new cluster with label `C` from the seed point `P`.
        
        This function searches through the dataset to find all points that belong
        to this new cluster. When this function returns, cluster `C` is complete.
        
        Parameters:
        `D`      - The dataset (a list of vectors)
        `labels` - List storing the cluster labels for all dataset points
        `P`      - Index of the seed point for this new cluster
        `NeighborPts` - All of the neighbors of `P`
        `C`      - The label for this new cluster.  
        `eps`    - Threshold distance
        `MinPts` - Minimum required number of neighbors
        '''

        # Assign the cluster label to the seed point.
        labels[P] = C
        
        # FIFO
        i = 0
        while i < len(NeighborPts):    
            
            # Get the next point from the queue.        
            Pn = NeighborPts[i]
        
            # If Pn was labelled NOISE during the seed search, then we
            # know it's not a branch point (it doesn't have enough neighbors), so
            # make it a leaf point of cluster C and move on.
            if labels[Pn] == -1:
                labels[Pn] = C
            
            # Otherwise, if Pn isn't already claimed, claim it as part of C.
            elif labels[Pn] == 0:
                # Add Pn to cluster C (Assign cluster label C).
                labels[Pn] = C
                
                # Find all the neighbors of Pn
                PnNeighborPts = self.region_query(Pn)
                
                # If Pn has at least MinPts neighbors, it's a branch point!
                # Add all of its neighbors to the FIFO queue to be searched. 
                if len(PnNeighborPts) >= self.minPts:
                    NeighborPts = NeighborPts + PnNeighborPts
                # If Pn *doesn't* have enough neighbors, then it's a leaf point.
                # Don't queue up it's neighbors as expansion points.
                #else:
                    # Do nothing                
                    #NeighborPts = NeighborPts               
            
            # Advance to the next point in the FIFO queue.
            i += 1        
        
        # We've finished growing cluster C!


    def region_query(self, P):
        '''
        Find all points in dataset `D` within distance `eps` of point `P`.
        
        This function calculates the distance between a point P and every other 
        point in the dataset, and then returns only those points which are within a
        threshold distance `eps`.
        '''
        neighbors = []
        
        # For each point in the dataset...
        for Pn in range(0, len(self.points)):
            
            # If the distance is below the threshold, add it to the neighbors list.
            if np.linalg.norm(self.points[P] - self.points[Pn]) < self.eps:
                neighbors.append(Pn)
        return neighbors
    
    def return_max(self, labels):
        values, counts = np.unique(labels, return_counts=True)
        if len(values) == 0 or (values[0] == -1 and len(values) == 1):
            return []
        idx = np.argmax(counts)
        if values[idx] == -1:
            idx = np.argmax(counts[1:]) + 1

        lines = []
        for i in range(len(labels)):
            if(labels[i] == values[idx]):
                lines.append(self.dbscan_dict[(self.points[i][0], self.points[i][1])])
        return lines


//--------------------
//Content of live_agri_warp.py
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import matplotlib.gridspec as gridspec
import cv2
import numpy as np
import pickle as pickle
import glob
import math
from moviepy.editor import *
from DBSCAN import *

ORIGINAL_SIZE = 1280, 720
WARPED_SIZE = 500, 600

# For temporal smoothing
left_buffer = []
right_buffer = []
buffer_size = 5

def getROI():
    #roi_points = np.array([[0, ORIGINAL_SIZE[1] - 25],
    #                   [ORIGINAL_SIZE[0], ORIGINAL_SIZE[1] - 25],
    #                   [ORIGINAL_SIZE[0] // 2 + 10, ORIGINAL_SIZE[1] - 540]])
    roi_points = np.array([[0, 360],
                       [1280, 360],
                       [1280, 665],
                       [0, 665]])
    roi = np.zeros((720, 1280), np.uint8) # uint8 good for 0-255 so good for small numbers like colors
    cv2.fillPoly(roi, [roi_points], 1)
    return roi

def fillAvgs(lines):
    l = []
    for i in range(len(lines)):
        line = lines[i]
        x1 = line[0]
        y1 = line[1]
        x2 = line[2]
        y2 = line[3]
        slope = (y2 - y1) / (x2 - x1)
        intercept = y1 - (slope * x1)
        l.append([slope, intercept])
        # cv2.line(img, (x1, y1), (x2, y2), (0, 255, 0), thickness = 2)
        return l

def getLines(img):
    roi = getROI()

    # Employing Gaussian Blur
    img = cv2.GaussianBlur(img,(3,3),2)
    kernel = np.ones((3,3),np.uint8)
    img = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)
    # Might need to skip horizontal lines when doing HoughLine

    # Canny + Hough Lines
    img_HLS = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)
    _h_channel = img_HLS[:, :, 0]
    _l_channel  = img_HLS[:, :, 1]
    _s_channel = img_HLS[:, :, 2]

    #ret, p = cv2.threshold(_l_channel,140, 255,cv2.THRESH_BINARY)
    #ret, q = cv2.threshold(_l_channel,160,255,cv2.THRESH_BINARY)
    #_l_channel = cv2.bitwise_xor(p, q)

    _h_channel = cv2.equalizeHist(_h_channel)

    low_thresh = 100
    high_thresh = 200
    # Better to do Canny on lightness channel
    _h_channel = cv2.morphologyEx(_h_channel, cv2.MORPH_CLOSE, kernel)
    _h_channel = cv2.GaussianBlur(_h_channel,(3,3),2)
    _h_channel = cv2.GaussianBlur(_h_channel,(3,3),2)

    kernel = np.ones((5,5),np.uint8)
    edges = cv2.Canny(_h_channel, low_thresh, high_thresh)
    edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)
    new_img = cv2.bitwise_and(edges, edges, mask=roi)
    lines = cv2.HoughLinesP(new_img, 2, np.pi/180, 60, None, 60, 100)
    return lines

def main(img):
    global left_buffer, right_buffer, buffer_size

    lines = getLines(img)

    if lines is None:
        return img

    left_av = []
    right_av = []
    dbscan_left = DBSCAN(50, 2)
    dbscan_right = DBSCAN(50, 2)

    for line in lines:
        for x1, y1, x2, y2 in line:
            # Average out the lines
            slope = (y2 - y1) / (x2 - x1)
            if abs(slope) > 5 or slope == 0 or abs(slope) < 0.1:
                pass
            else:
                if slope > 0:
                    dbscan_right.update(line)
                else:
                    dbscan_left.update(line)

    left_classes = dbscan_left.scan()
    left_lines = dbscan_left.return_max(left_classes)
    left_av = fillAvgs(left_lines)

    right_classes = dbscan_right.scan()
    right_lines = dbscan_right.return_max(right_classes)
    right_av = fillAvgs(right_lines)

    # Cont. Averaging Lines
    left_fitted_av = []
    right_fitted_av = []
    if left_av:
        left_fitted_av = np.average(left_av, axis=0)
    else:
        return img
    if right_av:
        right_fitted_av = np.average(right_av, axis=0)
    else:
        return img
    
    # Adding average line to buffer
    def add_line_to_buffer(line_buffer, line):
        line_buffer.append(line)
        return line_buffer[-buffer_size:]
    left_buffer = add_line_to_buffer(left_buffer, left_fitted_av)
    right_buffer = add_line_to_buffer(right_buffer, right_fitted_av)

    # Get mean of buffered lines
    left_fitted_av = np.mean(left_buffer, axis=0)
    right_fitted_av = np.mean(right_buffer, axis=0)
    # NOW WE HAVE SMOOTHED LINES AND WE PROCEED AS BEFORE.

    top = ORIGINAL_SIZE[1] - 700
    bot = ORIGINAL_SIZE[1] - 55
    y1 = ORIGINAL_SIZE[1] - 55
    y2 = ORIGINAL_SIZE[1] - 500
    try:
        # PLOTTING AND GETTING THE AVERAGED LINES.
        left_x1 = int((y1 - left_fitted_av[1]) / left_fitted_av[0])
        left_x2 = int((y2 - left_fitted_av[1]) / left_fitted_av[0])
        right_x1 = int((y1 - right_fitted_av[1]) / right_fitted_av[0])
        right_x2 = int((y2 - right_fitted_av[1]) / right_fitted_av[0])
        cv2.line(img, (left_x1, y1), (left_x2, int(y2)), (255, 0, 0), thickness = 2)
        cv2.line(img, (right_x1, y1), (right_x2, int(y2)), (255, 0, 0), thickness = 2)
    except:
        return img

    # Hard-coded src and dest pts
    src_pts = np.float32([[0, 360],
                      [1280, 360],
                      [1280, 665.      ],
                      [0, 665.      ]])
    dst_pts = np.float32([[0, 0], [WARPED_SIZE[0], 0],
                       [WARPED_SIZE[0], WARPED_SIZE[1]],
                       [0, WARPED_SIZE[1]]])
    # Draw ROI
    cv2.polylines(img, [src_pts.astype(np.int32)],True, (0,200,100), thickness=2)

    # INVERSE-PERSPECTIVE MAPPING TIME.
    src_pts[0] += [-1, 1]
    src_pts[1] += [1, 1]
    M = cv2.getPerspectiveTransform(src_pts, dst_pts)
    warped_img = cv2.warpPerspective(img, M, WARPED_SIZE)
    
    f = warped_img

    # Transform averaged points into warped coordinates.
    # Endpoints for averaged lines
    bot_left = np.array([left_x1, y1], dtype="float32")
    top_left = np.array([left_x2, int(y2)], dtype="float32")
    bot_right = np.array([right_x1, y1], dtype="float32")
    top_right = np.array([right_x2, int(y2)], dtype="float32")

    # Transforming above endpoints
    def transformPoints(p):
        return cv2.perspectiveTransform(np.array([[p]]), M, WARPED_SIZE).squeeze()
    
    bot_left = transformPoints(bot_left)
    top_left = transformPoints(top_left)
    bot_right = transformPoints(bot_right)
    top_right = transformPoints(top_right)
    cv2.line(f, bot_left.astype("int"), top_left.astype("int"), (0, 255, 0), 3)
    cv2.line(f, bot_right.astype("int"), top_right.astype("int"), (0, 255, 0), 3)

    mid_top = [int((top_left[0] + top_right[0]) / 2),
            int((top_left[1] + top_right[1]) / 2)]
    mid_bot = [int((bot_left[0] + bot_right[0]) / 2),
            int((bot_left[1] + bot_right[1]) / 2)]

    # Drawing mid-line
    cv2.line(f, mid_top, mid_bot, (0, 0, 255), 3)
    # Add current car trajectory
    traj_bot = [f.shape[1] // 2, 600]
    traj_top = [f.shape[1] // 2, 0]
    cv2.line(f,traj_bot, traj_top, (0, 0, 255), 3)
    x = traj_bot[0]
    mid_slope = 0
    if mid_top[0] - mid_bot[0] != 0:
        mid_slope = (mid_top[1] - mid_bot[1]) / (mid_top[0] - mid_bot[0])
    else:
        mid_slope = (mid_top[1] - mid_bot[1]) * 1000
    mid_int = mid_top[1] - mid_top[0] * mid_slope
    y = x * mid_slope + mid_int
    P = np.array([x, y])

    # Calculating pixel distance between averaged line and trajectory line.
    PA = np.array(traj_bot) - P
    PB = np.array(mid_bot) - P

    PB_mag = np.linalg.norm(PB)
    PB_unit = PB / PB_mag
    A_parallel = np.dot(PA, PB_unit) * PB_unit
    A_parallel_pt = A_parallel + P

    # Find Intercept
    vec = traj_bot - A_parallel_pt
    vec_mag = np.linalg.norm(vec)
    cv2.putText(img, str(vec_mag), (0, 200), cv2.FONT_HERSHEY_SIMPLEX ,  
                   1, (0, 0, 0), 2, cv2.LINE_AA) 

    return img

if __name__ == "__main__":
    clip  = VideoFileClip("../agri_videos/0123.mp4")
    mod_clip = clip.fl_image(main)

    mod_clip.write_videofile("../agri_videos/output_video.mp4", audio=False)
//--------------------
//Content of live_warp.py
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import matplotlib.gridspec as gridspec
import cv2
import numpy as np
import pickle as pickle
import glob
import math
from moviepy.editor import *

ORIGINAL_SIZE = 1280, 720
WARPED_SIZE = 500, 600

def getROI():
    roi_points = np.array([[200, ORIGINAL_SIZE[1] - 55],
                       [ORIGINAL_SIZE[0] - 200, ORIGINAL_SIZE[1] - 55],
                       [ORIGINAL_SIZE[0] // 2, ORIGINAL_SIZE[1] - 295]])
    roi = np.zeros((720, 1280), np.uint8) # uint8 good for 0-255 so good for small numbers like colors
    cv2.fillPoly(roi, [roi_points], 1)
    return roi

def getLines(img):
    roi = getROI()

    # Employing Gaussian Blur
    img = cv2.GaussianBlur(img,(3,3),2)
    # Might need to skip horizontal lines when doing HoughLine

    # Canny + Hough Lines
    img_HLS = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)
    _h_channel = img_HLS[:, :, 0]
    _l_channel  = img_HLS[:, :, 1]
    _s_channel = img_HLS[:, :, 2]

    #ret, p = cv2.threshold(_l_channel,140, 255,cv2.THRESH_BINARY)
    #ret, q = cv2.threshold(_l_channel,160,255,cv2.THRESH_BINARY)
    #_l_channel = cv2.bitwise_xor(p, q)

    _l_channel = cv2.equalizeHist(_l_channel)

    low_thresh = 100
    high_thresh = 200
    # Better to do Canny on lightness channel
    edges = cv2.Canny(_l_channel, low_thresh, high_thresh)
    new_img = cv2.bitwise_and(edges, edges, mask=roi)
    lines = cv2.HoughLinesP(new_img, 2, np.pi/180, 30, None, 180, 120)
    return lines

def main(img):
    lines = getLines(img)

    if lines is None:
        return img

    left_av = []
    right_av = []
    for line in lines:
        for x1, y1, x2, y2 in line:
            # Average out the lines
            slope = (y2 - y1) / (x2 - x1)
            intercept = y1 - (slope * x1)
            if abs(slope) > 5:
                pass
            elif slope > 0:
                right_av.append([slope, intercept])
                #cv2.line(img, (x1, y1), (x2, y2), (255, 0, 0), thickness = 2)
            else:
                left_av.append([slope, intercept])
                #cv2.line(img, (x1, y1), (x2, y2), (0, 255, 0), thickness = 2)
    
    # Hard-coded VP
    vp = [664.16125, 419.31366]
    top = vp[1] + 65
    bot = ORIGINAL_SIZE[1] - 55

    # Cont. Averaging Lines
    left_fitted_av = []
    right_fitted_av = []
    if left_av:
        left_fitted_av = np.average(left_av, axis=0)
    else:
        return img
    if right_av:
        right_fitted_av = np.average(right_av, axis=0)
    else:
        return img

    y1 = bot
    y2 = top
    try:
        left_x1 = int((y1 - left_fitted_av[1]) / left_fitted_av[0])
        left_x2 = int((y2 - left_fitted_av[1]) / left_fitted_av[0])
        right_x1 = int((y1 - right_fitted_av[1]) / right_fitted_av[0])
        right_x2 = int((y2 - right_fitted_av[1]) / right_fitted_av[0])
        cv2.line(img, (left_x1, y1), (left_x2, int(y2)), (255, 0, 0), thickness = 2)
        cv2.line(img, (right_x1, y1), (right_x2, int(y2)), (255, 0, 0), thickness = 2)
    except:
        return img

    # Hard-coded src and dest pts
    src_pts = np.float32([[ 486.2556, 488.81726], 
                          [ 788.2556, 488.81726], 
                          [1196.1389, 665.     ],
                          [  78.37237, 665.     ]])
    dst_pts = np.float32([[0, 0], [WARPED_SIZE[0], 0],
                       [WARPED_SIZE[0], WARPED_SIZE[1]],
                       [0, WARPED_SIZE[1]]])
    # Draw Trapezoid
    cv2.polylines(img, [src_pts.astype(np.int32)],True, (0,200,100), thickness=2)

    src_pts[0] += [-1, 1]
    src_pts[1] += [1, 1]
    M = cv2.getPerspectiveTransform(src_pts, dst_pts)
    warped_img = cv2.warpPerspective(img, M, WARPED_SIZE)
    
    f = warped_img

    # Transform averaged points into warped coordinates.
    # Endpoints for averaged lines
    bot_left = np.array([left_x1, y1], dtype="float32")
    top_left = np.array([left_x2, int(y2)], dtype="float32")
    bot_right = np.array([right_x1, y1], dtype="float32")
    top_right = np.array([right_x2, int(y2)], dtype="float32")

    # Transforming above endpoints
    bot_left = cv2.perspectiveTransform(np.array([[bot_left]]), M, WARPED_SIZE).squeeze()
    top_left = cv2.perspectiveTransform(np.array([[top_left]]), M, WARPED_SIZE).squeeze()
    bot_right = cv2.perspectiveTransform(np.array([[bot_right]]), M, WARPED_SIZE).squeeze()
    top_right = cv2.perspectiveTransform(np.array([[top_right]]), M, WARPED_SIZE).squeeze()
    cv2.line(f, bot_left.astype("int"), top_left.astype("int"), (0, 255, 0), 3)
    cv2.line(f, bot_right.astype("int"), top_right.astype("int"), (0, 255, 0), 3)

    mid_top = [int((top_left[0] + top_right[0]) / 2),
            int((top_left[1] + top_right[1]) / 2)]
    mid_bot = [int((bot_left[0] + bot_right[0]) / 2),
            int((bot_left[1] + bot_right[1]) / 2)]

    # Drawing mid-line
    cv2.line(f, mid_top, mid_bot, (0, 0, 255), 3)
    # Add current car trajectory
    traj_bot = [f.shape[1] // 2, 600]
    traj_top = [f.shape[1] // 2, 0]
    cv2.line(f,traj_bot, traj_top, (0, 0, 255), 3)
    x = traj_bot[0]
    mid_slope = 0
    if mid_top[0] - mid_bot[0] != 0:
        mid_slope = (mid_top[1] - mid_bot[1]) / (mid_top[0] - mid_bot[0])
    else:
        mid_slope = (mid_top[1] - mid_bot[1]) * 1000
    mid_int = mid_top[1] - mid_top[0] * mid_slope
    y = x * mid_slope + mid_int
    P = np.array([x, y])

    # Calculating pixel distance between averaged line and trajectory line.
    PA = np.array(traj_bot) - P
    PB = np.array(mid_bot) - P

    PB_mag = np.linalg.norm(PB)
    PB_unit = PB / PB_mag
    A_parallel = np.dot(PA, PB_unit) * PB_unit
    A_parallel_pt = A_parallel + P

    # Find Intercept
    vec = traj_bot - A_parallel_pt
    vec_mag = np.linalg.norm(vec)
    cv2.putText(img, str(vec_mag), (0, 200), cv2.FONT_HERSHEY_SIMPLEX ,  
                   1, (0, 255, 0), 2, cv2.LINE_AA) 

    return img

if __name__ == "__main__":
    clip  = VideoFileClip("urmom.mp4")
    mod_clip = clip.fl_image(main)

    mod_clip.write_videofile("output_video.mp4", audio=False)
//--------------------
//Content of warp.py
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import matplotlib.gridspec as gridspec
import cv2
import numpy as np
import pickle as pickle
import glob
import math

ORIGINAL_SIZE = 640, 480
UNWARPED_SIZE = 500, 600

imgs = ["test_images1/1.jpg"]
img = mpimg.imread(imgs[0])

#plt.imshow(img)
#plt.show()

#################################################################

Lhs = np.zeros((2, 2), dtype = np.float32)
Rhs = np.zeros((2, 1), dtype = np.float32)
x_max = 0
x_min = 2555
# The 2 lines come from Agronav. You do the vp calcs and the warps
# with the two lines. The Agronav ref line is in the image. The two lines
# are not and just used to warp.
lines = [[0, 170, 630, 310],
         [0, 300, 630, 170]]
a = 0

for line in lines:
  x1 = line[0]
  y1 = line[1]
  x2 = line[2]
  y2 = line[3]

  a+=1
  # Find the norm (the distances between the two points)
  normal = np.array([[-(y2-y1)], [x2-x1]], dtype = np.float32) # question about this implementation [a, b] . [-b, a] = 0
  normal = normal / np.linalg.norm(normal)  # = sqrt(a1^2 + a2^2 + a3^2 + . . . )

  # Normal is 2x1 and is a vector v . w = vT . w

  pt = np.array([[x1], [y1]], dtype = np.float32)

  outer = np.matmul(normal, normal.T)

  Lhs += outer
  Rhs += np.matmul(outer, pt) #use matmul for matrix multiply and not dot product
  # Just keep summing these guys up like how you and they derived it.

  #cv2.line(img, (x1, y1), (x2, y2), (255, 0, 0), thickness = 30)

  x_iter_max = max(x1, x2)
  x_iter_min = min(x1, x2)
  x_max = max(x_max, x_iter_max)
  x_min = min(x_min, x_iter_min)

# Calculate Vanishing Point
vp = np.matmul(np.linalg.inv(Lhs), Rhs)
#plt.plot(vp[0], vp[1], 'c^')
#plt.imshow(img)
#plt.title('Vanishing Point visualization')
#plt.show()
print("Done!")

###############################################################
def find_pt_inline(p1, p2, y):
    """
    Here we use point-slope formula in order to find a point that is present on the line
    that passes through our vanishing point (vp).
    input: points p1, p2, and y. They come is as tuples [x, y]
    We then use the point-slope formula: y - b = m(x - a)
    y: y-coordinate of desired point on the line
    x: x-coordinate of desired point on the line
    m: slope
    b: y-coordinate of p1
    a: x-coodrinate of p1
    x = p1x + (1/m)(y - p1y)
    """
    m_inv = (p2[0] - p1[0]) / float(p2[1] - p1[1])
    Δy = (y - p1[1])
    x = p1[0] + m_inv * Δy
    return [np.array(x), np.array(np.float32([y]))]


top = vp[1] + 65
bot = ORIGINAL_SIZE[1] - 40
print(bot)

# Make a large width so that you can grab the lines on the challenge video
width = 500

p1 = [vp[0] - width/2, top]
p2 = [vp[0] + width/2, top]
p3 = find_pt_inline(p2, vp, bot)
p4 = find_pt_inline(p1, vp, bot)

print(p1, p3)
src_pts = np.float32([p1, p2, p3, p4])

# Mapping one corner to 0,0 so the warped image is the entire image now.
dst_pts = np.float32([[0, 0], [UNWARPED_SIZE[0], 0],
                       [UNWARPED_SIZE[0], UNWARPED_SIZE[1]],
                       [0, UNWARPED_SIZE[1]]])

# Draw Trapezoid
cv2.polylines(img, [src_pts.astype(np.int32)],True, (0,200,100), thickness=5)
#plt.plot(p1[0], p1[1], 'r+')
#plt.plot(p2[0], p2[1], 'c^')
#plt.plot(p3[0], p3[1], 'r^')
#plt.plot(p4[0], p4[1], 'g^')
#plt.title('Trapezoid For Perspective Transform')
#plt.imshow(img)
#plt.show()

############################################################################################

# H is the homography matrix
M_inv = cv2.getPerspectiveTransform(dst_pts, src_pts)
M = cv2.getPerspectiveTransform(src_pts, dst_pts)
warped = cv2.warpPerspective(img, M, UNWARPED_SIZE)
plt.imshow(warped)
plt.show()

############################################################################################

reg, mask = cv2.threshold(warped[:,:,0], 245, 255, cv2.THRESH_BINARY)
plt.imshow(mask)
plt.show()

lines = cv2.HoughLinesP(mask, 0.5, np.pi/180, 100, 50, 50)
line = lines[0].flatten()

# Transform the center bottom of the screen using the transfom matrix
pixel_coordinates = np.array([[ORIGINAL_SIZE[0] / 2, bot]], dtype=np.float32)
pixel_coordinates = pixel_coordinates.reshape(-1, 1, 2)
coords = cv2.perspectiveTransform(pixel_coordinates, M, UNWARPED_SIZE).squeeze()
#print(coords)

A = line[2:]
B = line[:2]
AB = np.subtract(B, A)
AC = np.subtract(coords, A)
#print(AB, AC)

mag = np.linalg.norm(AB)
tmp = np.dot(AB, AC) / (mag**2)
AB_parallel = tmp * AB
inter = AB_parallel + A
print("Distance in pixels:", math.dist(coords, inter))
//--------------------
//Content of warp2.py
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import matplotlib.gridspec as gridspec
import cv2
import numpy as np
import pickle as pickle
import glob
import math

ORIGINAL_SIZE = 1280, 720
WARPED_SIZE = 500, 600

imgs = ["test_images2/frame0312.jpg"]
#imgs = ["test_images2/straight_lines1.jpg"]
img = mpimg.imread(imgs[0])

# Get a new ROI for image, on which we apply Hough Transform.
# y=425 the upper bound (original_size[0] - 295).
# y=665 the lower bound (original_size[1] - 55).
# Make a triangle shape to identify lines that go off into vanishing point.
# MAKE NOTE THAT YOU ALWAYS DO WIDTH (X) THEN HEIGHT (Y).
roi_points = np.array([[300, ORIGINAL_SIZE[1] - 55],
                       [ORIGINAL_SIZE[0] - 300, ORIGINAL_SIZE[1] - 55],
                       [ORIGINAL_SIZE[0] // 2, ORIGINAL_SIZE[1] - 295]])
roi = np.zeros((720, 1280), np.uint8) # uint8 good for 0-255 so good for small numbers like colors
cv2.fillPoly(roi, [roi_points], 1)

# Employing Gaussian Blur
img = cv2.GaussianBlur(img,(3,3),2)

#img = cv2.addWeighted(img, 2.3, np.zeros(img.shape, img.dtype), 0, 4)
#plt.imshow(img)
#plt.show() 

# Might need to skip horizontal lines when doing HoughLine

# Canny + Hough Lines
img_HLS = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)
_h_channel = img_HLS[:, :, 0]
_l_channel  = img_HLS[:, :, 1]
_s_channel = img_HLS[:, :, 2]

# print(_l_channel[558][412])

#ret, p = cv2.threshold(_l_channel,140, 255,cv2.THRESH_BINARY)
#ret, q = cv2.threshold(_l_channel,160,255,cv2.THRESH_BINARY)
#_l_channel = cv2.bitwise_xor(p, q)

_l_channel = cv2.equalizeHist(_l_channel)

low_thresh = 100
high_thresh = 200
# Better to do Canny on lightness channel
edges = cv2.Canny(_l_channel, high_thresh, low_thresh)
new_img = cv2.bitwise_and(edges, edges, mask=roi)
plt.imshow(new_img)
plt.show()
lines = cv2.HoughLinesP(new_img, 2, np.pi/180, 30, None, 180, 120)

Lhs = np.zeros((2, 2), dtype = np.float32)
Rhs = np.zeros((2, 1), dtype = np.float32)
x_max = 0
x_min = 2555    
left_av = []
right_av = []
for line in lines:
    for x1, y1, x2, y2 in line:
        # Find the norm (the distances between the two points)
        normal = np.array([[-(y2-y1)], [x2-x1]], dtype = np.float32) # question about this implementation
        normal = normal / np.linalg.norm(normal)
        pt = np.array([[x1], [y1]], dtype = np.float32)
        outer = np.matmul(normal, normal.T)
        
        Lhs += outer
        Rhs += np.matmul(outer, pt) #use matmul for matrix multiply and not dot product

        # Average out the lines
        slope = (y2 - y1) / (x2 - x1)
        intercept = y1 - (slope * x1)
        if abs(slope) > 5:
            pass
        elif slope > 0:
            right_av.append([slope, intercept])
            cv2.line(img, (x1, y1), (x2, y2), (255, 0, 0), thickness = 2)
        else:
            left_av.append([slope, intercept])
            cv2.line(img, (x1, y1), (x2, y2), (0, 255, 0), thickness = 2)

        x_iter_max = max(x1, x2)
        x_iter_min = min(x1, x2)
        x_max = max(x_max, x_iter_max)
        x_min = min(x_min, x_iter_min)
width = x_max - x_min
print('width : ', width)
# Calculate Vanishing Point
vp = np.matmul(np.linalg.inv(Lhs), Rhs)
vp = vp.flatten()

print('vp is : ', vp)
plt.plot(vp[0], vp[1], 'c^')

plt.imshow(img)
plt.show()

# Cont. Averaging Lines
left_fitted_av = np.average(left_av, axis=0)
right_fitted_av = np.average(right_av, axis=0)

# Drawing up source points for perspective warps
def find_pt_inline(p1, p2, y):
    """
    Here we use point-slope formula in order to find a point that is present on the line
    that passes through our vanishing point (vp). 
    input: points p1, p2, and y. They come is as tuples [x, y]
    We then use the point-slope formula: y - b = m(x - a)
    y: y-coordinate of desired point on the line
    x: x-coordinate of desired point on the line
    m: slope
    b: y-coordinate of p1
    a: x-coodrinate of p1
    x = p1x + (1/m)(y - p1y)
    """
    m_inv = (p2[0] - p1[0]) / float(p2[1] - p1[1])
    Δy = (y - p1[1])
    x = p1[0] + m_inv * Δy
    return [x, y]

top = vp[1] + 65
bot = ORIGINAL_SIZE[1] - 55

#print(900*right_av[0][0] + right_av[0][1])
#cv2.line(img, (0, -38), (900, 1188), (0, 0, 255), 3)


# Cont. Averaging Lines
y1 = bot
y2 = top
left_x1 = int((y1 - left_fitted_av[1]) / left_fitted_av[0])
left_x2 = int((y2 - left_fitted_av[1]) / left_fitted_av[0])
right_x1 = int((y1 - right_fitted_av[1]) / right_fitted_av[0])
right_x2 = int((y2 - right_fitted_av[1]) / right_fitted_av[0])
cv2.line(img, (left_x1, y1), (left_x2, int(y2)), (255, 0, 0), thickness = 2)
cv2.line(img, (right_x1, y1), (right_x2, int(y2)), (255, 0, 0), thickness = 2)

# Make a large width so that you can grab the lines on the challenge video
width = 300

p1 = [vp[0] - width/2, top]
p2 = [vp[0] + width/2, top]
p3 = find_pt_inline(p2, vp, bot)
p4 = find_pt_inline(p1, vp, bot)

src_pts = np.float32([p1, p2, p3, p4])
src_pts = np.float32([[ 462.2556, 487.81726 ],
                      [ 812.2556, 487.81726 ],
                      [1289.286, 665.      ],
                      [ -14.774837, 665.      ]])

dst_pts = np.float32([[0, 0], [WARPED_SIZE[0], 0],
                       [WARPED_SIZE[0], WARPED_SIZE[1]],
                       [0, WARPED_SIZE[1]]])

# Draw Trapezoid
cv2.polylines(img, [src_pts.astype(np.int32)],True, (0,200,100), thickness=5)
plt.plot(p1[0], p1[1])
plt.plot(p2[0], p2[1])
plt.plot(p3[0], p3[1])
plt.plot(p4[0], p4[1])
plt.title('Trapezoid For Perspective Transform')

src_pts[0] += [-1, 1]
src_pts[1] += [1, 1]
M = cv2.getPerspectiveTransform(src_pts, dst_pts)
warped_img = cv2.warpPerspective(img, M, WARPED_SIZE)
f = warped_img
# M is what you will be using from now on.

# Next steps ...
# 1) Find mid-line between the two lane lines, serving as our reference line.
# 2) Warp and then hough for the reference line.
# 3) We already know the position of the current trajectory in warp (still just middle
#    of the image). Do some linear algebra to get distance in pixels.
# 4) Also still need to figure out pixel2meter.
#   a) Split project into 2: 1 for pixel2meter and 2 for running livestream

# Transform averaged points into warped coordinates.
# Endpoints for averaged lines
bot_left = np.array([left_x1, y1], dtype="float32")
top_left = np.array([left_x2, int(y2)], dtype="float32")
bot_right = np.array([right_x1, y1], dtype="float32")
top_right = np.array([right_x2, int(y2)], dtype="float32")

# Transforming above endpoints
bot_left = cv2.perspectiveTransform(np.array([[bot_left]]), M, WARPED_SIZE).squeeze()
top_left = cv2.perspectiveTransform(np.array([[top_left]]), M, WARPED_SIZE).squeeze()
bot_right = cv2.perspectiveTransform(np.array([[bot_right]]), M, WARPED_SIZE).squeeze()
top_right = cv2.perspectiveTransform(np.array([[top_right]]), M, WARPED_SIZE).squeeze()
cv2.line(f, bot_left.astype("int"), top_left.astype("int"), (0, 255, 0), 3)
cv2.line(f, bot_right.astype("int"), top_right.astype("int"), (0, 255, 0), 3)

mid_top = [int((top_left[0] + top_right[0]) / 2),
         int((top_left[1] + top_right[1]) / 2)]
mid_bot = [int((bot_left[0] + bot_right[0]) / 2),
         int((bot_left[1] + bot_right[1]) / 2)]

# Drawing mid-line
cv2.line(f, mid_top, mid_bot, (0, 0, 255), 3)
# Add current car trajectory
traj_bot = [f.shape[1] // 2, 600]
traj_top = [f.shape[1] // 2, 0]
cv2.line(f,traj_bot, traj_top, (0, 0, 255), 3)
x = traj_bot[0]
mid_slope = 0
if mid_top[0] - mid_bot[0] != 0:
    mid_slope = (mid_top[1] - mid_bot[1]) / (mid_top[0] - mid_bot[0])
else:
    mid_slope = (mid_top[1] - mid_bot[1]) * 1000
mid_int = mid_top[1] - mid_top[0] * mid_slope
y = x * mid_slope + mid_int
P = np.array([x, y])

# Calculating pixel distance between averaged line and trajectory line.
PA = np.array(traj_bot) - P
PB = np.array(mid_bot) - P

PB_mag = np.linalg.norm(PB)
PB_unit = PB / PB_mag
A_parallel = np.dot(PA, PB_unit) * PB_unit
A_parallel_pt = A_parallel + P

# Find Intercept

cv2.line(f,traj_bot, A_parallel_pt.astype("int"), (0, 0, 255), 3)

plt.imshow(f)
plt.show()





//--------------------
